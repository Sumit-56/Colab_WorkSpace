{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Tsc8kTnNMDGU_iCn8BRkO3QT5quyLRCl",
      "authorship_tag": "ABX9TyMldaVrK2KKMCtJkG8Z12iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumit-56/Colab_WorkSpace/blob/main/Complete_TSA_and_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What is Time Series Data?\n",
        "Time series data is a collection of observations recorded over a sequence of time. This data is typically ordered chronologically and can be used to analyze trends, seasonality, and other patterns that evolve over time. Examples include stock prices, weather data, and website traffic."
      ],
      "metadata": {
        "id": "BJ06kr6U3LUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "006r3SX62ZIK"
      },
      "outputs": [],
      "source": [
        "#import library\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/bitcoin_price.csv')\n",
        "df['Date'] = pd.to_datetime(df['Date'], format=\"%Y-%m-%d\")\n",
        "df.set_index('Date', inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "VpRSqz7T6zP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Time series index\n",
        " we need to convert the Date column to a datetime format and then set it as the index of the DataFrame."
      ],
      "metadata": {
        "id": "OFeW0FOA7Pb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert 'date' to a datetime and set as index\n",
        "df['Date'] = pd.to_datetime(df['Date'], format=\"%Y-%m-%d\")\n",
        "df.set_index('Date', inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aMfP1INU6-NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data and set the index\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/bitcoin_price.csv', index_col='Date', parse_dates=True)\n",
        "df1.index"
      ],
      "metadata": {
        "id": "XK1jsWQh_Y_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Resampling\n",
        "Upsample: Increase the frequency (e.g., from daily to hourly). This often involves creating new data points through interpolation.\n",
        "Downsample: Decrease the frequency (e.g., from daily to monthly or yearly). This typically involves aggregating data over the new, lower frequency intervals (e.g., calculating the mean, sum, or other statistics for each month).\n",
        "Resampling is a crucial step in time series analysis because it allows you to analyze data at different granularities, align time series with different frequencies, and prepare data for various modeling techniques. In your notebook, you used df.resample('M').mean() to downsample your daily Bitcoin price data to a monthly frequency and calculate the mean for each month"
      ],
      "metadata": {
        "id": "A3i5hvAfCqYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling to monthly frequency and calculate the mean closing price\n",
        "df.resample('ME').mean()"
      ],
      "metadata": {
        "id": "CBt-OuVxAxK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploring data"
      ],
      "metadata": {
        "id": "apdqVRBYoWJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 day rolling average of closing price\n",
        "df['7_day_rolling'] = df['Close'].rolling(window =7).mean()\n",
        "df[['Close', '7_day_rolling']].loc['2023'].plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8RN5U_pRCV9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fins out the highest avg month\n",
        "df.resample('M').mean()['Close'].idxmax()"
      ],
      "metadata": {
        "id": "p8CdTA5WoigQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate daily return\n",
        "df['daily_returns'] = df['Close'].pct_change()*100"
      ],
      "metadata": {
        "id": "1jMBB1NZrOs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#days with moret than 10% change in closing price\n",
        "df[df['daily_returns']>10].head(3)"
      ],
      "metadata": {
        "id": "oaGyXeSjrmgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data  Visualization"
      ],
      "metadata": {
        "id": "VnMgvoXcsd5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#daily closing priceplot\n",
        "df['Close'].plot(title=\"Daily Closing Price\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sU_DSIdesGh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the yearly volume\n",
        "df.resample('YE').sum().plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DvtQWqPTspRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting closing price and 30 day rolling volume\n",
        "df['30_day_rolling_vol'] = df['Volume'].rolling(window = 30).mean()\n",
        "df['30_day_rolling_vol'].plot(legend=True)\n",
        "ax = df['Close'].plot(secondary_y=True, legend = True)\n",
        "ax.set_ylabel('Volume')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4lFc45MDtw8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation between close and 30 day rolling\n",
        "df33 = df[['Close','30_day_rolling_vol']].corr()"
      ],
      "metadata": {
        "id": "-Rql-uBmuWYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df33.plot()"
      ],
      "metadata": {
        "id": "XtucPc20vFTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Manipulation"
      ],
      "metadata": {
        "id": "pfFigiRjvoMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "lhDbJNJGvdNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract time variables\n",
        "df['year'] = df.index.year\n",
        "df['month'] = df.index.month\n",
        "df['day'] = df.index.day\n",
        "df['weekday'] = df.index.weekday\n",
        "df['weekday_numeric'] = df.index.weekday\n",
        "df['is_weekend'] = df.index.weekday > 4\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GfpLtfIvwCKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering - Lagged Values\n",
        "Feature engineering is the process of creating new features from existing data to improve the performance of machine learning models. In the context of time series data, this often involves extracting relevant information from the time index, such as the year, month, day, or day of the week, as you have done in your notebook. It can also involve creating lagged variables, rolling averages, or other aggregations to capture temporal dependencies and patterns."
      ],
      "metadata": {
        "id": "OtRZo9nkyMeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close_lag1'] = df['Close'].shift(1)\n",
        "df['Close_lag2'] = df['Close'].shift(2)"
      ],
      "metadata": {
        "id": "5ajDTYTZx5ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seasonal Decomposition\n",
        "Seasonal decomposition is a technique used in time series analysis to break down a time series into its underlying components: trend, seasonality, and residual (or remainder).\n",
        "\n",
        "* ***Trend***: The long-term movement in the data.\n",
        "\n",
        "* ***Seasonality***: The repeating patterns or cycles within a fixed period (e.g., daily, monthly, yearly).\n",
        "\n",
        "* ***Residual***: The irregular or random fluctuations in the data that are not explained by the trend or seasonality.\n",
        "\n",
        "By decomposing a time series, we can better understand the individual components that influence the data and use this information for forecasting or further analysis.\n",
        "\n",
        "## Types of Seasonality\n",
        "There are two main types of seasonal decomposition:\n",
        "\n",
        "* ***Additive Decomposition:*** This model is used when the amplitude of the seasonal fluctuations is roughly constant over time. The formula is:\n",
        "`Y(t) = T(t) + S(t) + R(t)`\n",
        "\n",
        " Where:\n",
        "Y(t) is the observed value at time t\n",
        "T(t) is the trend component at time t\n",
        "S(t) is the seasonal component at time t\n",
        "R(t) is the residual component at time t\n",
        "* ***Multiplicative Decomposition:*** This model is used when the amplitude of the seasonal fluctuations changes proportionally to the level of the series (e.g., the fluctuations get larger as the overall value of the time series increases). The formula is: `Y(t) = T(t) * S(t) * R(t)`"
      ],
      "metadata": {
        "id": "6KAFHYgKzIHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seasonality\n",
        "Seasonality refers to the repeating patterns or cycles that occur within a fixed period. These patterns are predictable and tend to repeat themselves at regular intervals.\n",
        "\n",
        "For example, in your Bitcoin price data, you might observe:\n",
        "\n",
        "* Daily seasonality: Higher trading volume during certain hours of the day.\n",
        "* Weekly seasonality: Different price movements on weekends compared to weekdays.\n",
        "* Yearly seasonality: Price trends that tend to repeat around certain times of the year (e.g., holiday seasons).\n",
        "\n",
        "period()\n",
        "* 12 for monthly\n",
        "* 24 for hourly\n",
        "* 7 or 365 for daily, but 7 is preferred\n",
        "* 52 for weekly\n",
        "* 4 for quartely\n",
        "* 5 for weekdays"
      ],
      "metadata": {
        "id": "NgstAMz_1Oxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import month_plot, quarter_plot\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose"
      ],
      "metadata": {
        "id": "IiIs37F1zEcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the monyhly seasonality\n",
        "month_plot(df['Close'].resample('M').mean(), ylabel='Closing Price')"
      ],
      "metadata": {
        "id": "3ncL__Bt1v8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Quarter plot\n",
        "quarter_plot(df['Close'].resample('Q').mean())"
      ],
      "metadata": {
        "id": "0zAPVIKS17BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load new data\n",
        "df_choco = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/choco_monthly_revenue.csv')\n",
        "df_choco.head()"
      ],
      "metadata": {
        "id": "b-B5BC9I3Chw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_choco['Month with Year'] = pd.to_datetime(df_choco['Month with Year'])\n",
        "df_choco.set_index('Month with Year', inplace=True)\n",
        "month_plot(df_choco['revenue'], ylabel='Revenue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-6KXTW5C38SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seasonal decomposition plots for bitcoin data\n",
        "decomposition = seasonal_decompose(df_choco['revenue'], model = 'multiplicative', period = 12)\n",
        "fig = decomposition.plot()\n",
        "fig.set_size_inches(11.5, 10.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AtdWhAzF4ndx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}